{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "618978ff-371e-4c05-a478-a7c49e49dcbe",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "\n",
    "In this project, we built a software test automation tool using LLM. The tool can generate unit tests, integration tests taking into account the order of integration, and regression tests. In the case of a regression test, LLM must perform a minor and a major modification.\n",
    "\n",
    "\n",
    "* Unit testing: Generate all the unit testing\n",
    "* Integration testing\n",
    "* * Determine an integration order (integration plan)\n",
    "  * Develop the corresponding unit tests\n",
    "  * Develop the corresponding integration tests\n",
    "\n",
    "* Regression testing\n",
    "* * Perform minor modifications (add an attribute, remove an attribute, add a method) and see the impact on the previously implemented tests\n",
    "  * Perform major modifications (change of collaboration between classes) and see the impact on previously implemented tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c72aa674-3195-451b-9d83-13b24ab844a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import anthropic\n",
    "import io\n",
    "import subprocess\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d5748db-fa6a-4a3a-b7a9-9b6f5f8250e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display, update_display\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig,AutoModel,AutoProcessor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffeba01b-3f55-4605-89ef-1fe936f7a657",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Huggin Face API Key exists and begins hf_GYeH\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "load_dotenv('.env.anthropic', override=True)\n",
    "load_dotenv('../.env.anthropic', override=True)\n",
    "load_dotenv('../.env.hugging', override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "hugging_face_api_key = os.getenv('HUGGING_FACE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "    \n",
    "if hugging_face_api_key:\n",
    "    print(f\"Huggin Face API Key exists and begins {hugging_face_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Hugging Face API Key not set\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52a5d792-ba33-414c-bf81-b515b5e6bc45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "openai = OpenAI()\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a8760c1-fc8a-4b92-81cd-85f88672217a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "openai_model = \"gpt-4o-mini\"\n",
    "claude_model = \"claude-3-haiku-20240307\"\n",
    "qwen = \"Qwen/CodeQwen1.5-7B-Chat\"\n",
    "llama = \"meta-llama/Llama-3.2-3B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98ec3913-37d7-473e-880a-bccb0e2df7ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt = \"You are a software test automation tool.\"\n",
    "system_prompt += \"Your goal is to generate a variety of test tasks including generating test cases, enhancing existing test cases, and even refactoring outdated scripts.\"\n",
    "system_prompt += \"You should generate unit testing for each function that exist in the class.\"\n",
    "system_prompt += \"You should generate integration testings by takin into account integration order.  Generate the corresponding unit tests  and the corresponding integration tests\"\n",
    "system_prompt += \"You should perform regression testing. In a case of regression testing you should perform a minor and a major modification.\"\n",
    "system_prompt += \"For the minor modification you should add an attribute, remove an attribute, add a method and see the impact on the previously implemented tests.\"\n",
    "system_prompt += \"For the major modifications you shoud change the collaboration between classes and see the impact on previously implemented tests.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18ec8b0f-82fd-4bf9-9537-2e428e923f8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a software test automation tool.Your goal is to generate a variety of test tasks including generating test cases, enhancing existing test cases, and even refactoring outdated scripts.You should generate unit testing for each function that exist in the class.You should generate integration testings by takin into account integration order.  Generate the corresponding unit tests  and the corresponding integration testsYou should perform regression testing. In a case of regression testing you should perform a minor and a major modification.For the minor modification you should add an attribute, remove an attribute, add a method and see the impact on the previously implemented tests.For the major modifications you shoud change the collaboration between classes and see the impact on previously implemented tests.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9cf869c-331b-4a36-bcd0-6b043797a1df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def user_prompt(code):\n",
    "    user_prompt = \"Generate a unit testing, integration testing, regression testing.\"\n",
    "    user_prompt += \"Do not add comments to explain any code.\"\n",
    "    user_prompt = code\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1dcf4929-ef1b-4596-a269-145e1cb06962",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def messages(code):\n",
    "    return [\n",
    "        {\"role\":\"system\",\"content\":system_prompt},\n",
    "        {\"role\":\"user\",\"content\":user_prompt(code)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6351b4ab-13b5-43bd-bed9-ff82e8b11af9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save the code that have been generated into a text file\n",
    "def save_generated_code(code):\n",
    "    content = code.replace(\"```code\",\"\").replace(\"```\",\"\")\n",
    "    with open(\"automation.txt\", \"w\") as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee76699a-26d2-4445-91e3-16bf4ae59e76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate the test using gpt\n",
    "def generate_test_gpt(code):\n",
    "    stream = openai.chat.completions.create(model=openai_model,messages=messages(code),stream=True)\n",
    "    reply = \"\"\n",
    "    for chunk in stream:\n",
    "        fragment = chunk.choices[0].delta.content or \"\"\n",
    "        reply += fragment\n",
    "        yield reply\n",
    "    save_generated_code(reply)\n",
    "        #print(fragment, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1896d90e-1980-4af4-9651-e59bb6359569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the test using claude\n",
    "\n",
    "def generate_test_claude(code):\n",
    "    result = claude.messages.stream(\n",
    "        model = claude_model,\n",
    "        max_tokens = 2000,\n",
    "        system = system_prompt,\n",
    "        messages = [{\"role\":\"user\",\"content\":user_prompt(code)}]\n",
    "    )\n",
    "    \n",
    "    reply = \"\"\n",
    "    with result as stream:\n",
    "        for text in stream.text_stream:\n",
    "            reply += text\n",
    "            yield reply\n",
    "            #print(text, end=\"\", flush=True)\n",
    "        save_generated_code(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a9f876c-9bd7-422c-99f7-aa24f7acca1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_test(code, model):\n",
    "    if model==\"GPT\":\n",
    "        result = generate_test_gpt(code)\n",
    "    elif model==\"Claude\":\n",
    "        result = generate_test_claude(code)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    for stream_so_far in result:\n",
    "        yield stream_so_far "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64411cd9-2460-42e2-8561-9668bba8614a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "code = \"\"\"\n",
    " public class Calculator {\n",
    "\n",
    "        public int add(int a, int b) {\n",
    "            return a + b;\n",
    "        }\n",
    "\n",
    "         public double divide(int a, int b) {\n",
    "            if (b == 0) {\n",
    "                throw new ArithmeticException(\"Cannot divide by zero\");\n",
    "            }\n",
    "            return (double) a / b;\n",
    "        }\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f202084-7ce5-461d-8f24-8454783e446c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "91578611-07a0-4a30-971d-3233dfe6ee90",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7870\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7870/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as ui:\n",
    "    with gr.Row():\n",
    "        current_code = gr.Textbox(label=\"Code\",lines=10,value=code)\n",
    "        generated_code = gr.Textbox(label=\"Generated Test\",lines=10)\n",
    "    with gr.Row():\n",
    "        model = gr.Dropdown([\"GPT\",\"Claude\"],label=\"Select a model\",value=\"GPT\")\n",
    "        convert = gr.Button(\"Generate test\")\n",
    "    convert.click(generate_test,inputs=[current_code,model],outputs=[generated_code])\n",
    "    \n",
    "ui.launch(share=True)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
